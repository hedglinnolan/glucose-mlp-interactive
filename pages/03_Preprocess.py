"""
Page 03: Preprocessing Builder
Build sklearn Pipeline with ColumnTransformer.
Integrates coach recommendations for intelligent preprocessing suggestions.
"""
import streamlit as st
import pandas as pd
import numpy as np
import copy
import time
from typing import List, Dict, Any, Optional

from utils.session_state import (
    init_session_state, get_data, DataConfig, set_preprocessing_pipeline, set_preprocessing_pipelines,
    TaskTypeDetection,
)
from utils.storyline import render_progress_indicator, get_insights_by_category, add_insight, render_breadcrumb, render_page_navigation
from ml.pipeline import (
    build_preprocessing_pipeline,
    get_pipeline_recipe,
    get_feature_names_after_transform,
    build_unit_harmonization_config,
    build_plausibility_bounds,
    apply_plausibility_filter,
)
from ml.model_registry import get_registry
from data_processor import get_numeric_columns
from utils.theme import inject_custom_css, render_step_indicator, render_guidance

@st.cache_resource
def _get_registry_cached():
    return get_registry()
from utils.widget_helpers import safe_option_index

init_session_state()

st.set_page_config(page_title="Preprocessing", page_icon="‚öôÔ∏è", layout="wide")
inject_custom_css()
render_step_indicator(4, "Preprocessing")
st.title("‚öôÔ∏è Preprocessing Builder")
render_breadcrumb("03_Preprocess")
render_page_navigation("03_Preprocess")

# Progress indicator
render_progress_indicator("03_Preprocess")

df = get_data()
if df is None:
    st.warning("Please upload data in the Upload & Audit page first")
    st.stop()
if len(df) == 0 or len(df.columns) == 0:
    st.warning("Your dataset is empty. Please upload data with at least one row and one column.")
    st.stop()

# Guardrail: Preprocessing is only for prediction mode
task_mode = st.session_state.get('task_mode')
if task_mode != 'prediction':
    st.warning("‚ö†Ô∏è **Preprocessing is only available in Prediction mode.**")
    st.info("""
    Please go to the **Upload & Audit** page and select **Prediction** as your task mode.
    Preprocessing pipelines are used to prepare data for machine learning models.
    """)
    st.stop()

data_config: Optional[DataConfig] = st.session_state.get('data_config')
if data_config is None or not data_config.target_col:
    st.warning("Please select target and features in the Upload & Audit page first")
    st.stop()

# Identify feature types (safe access with defaults)
all_features = data_config.feature_cols if data_config else []
if not all_features:
    st.warning("No features selected. Please select features in the Upload & Audit page first")
    st.stop()

numeric_cols = get_numeric_columns(df)
numeric_features = [f for f in all_features if f in numeric_cols]
categorical_features = [f for f in all_features if f not in numeric_cols]

st.info(f"**Numeric features:** {len(numeric_features)} | **Categorical features:** {len(categorical_features)}")

# Get profile, insights, EDA results for recommendations
profile = st.session_state.get('dataset_profile')
coach_output = st.session_state.get('coach_output')
insights = get_insights_by_category()
eda_results = st.session_state.get('eda_results', {})
relevant_insights = [i for i in insights if i.get('category') in ['feature_relationships', 'data_quality']]

# EDA-based recommendation cues (for display next to options)
_eda_outliers = bool(profile and profile.features_with_outliers)
_eda_missing = bool(profile and profile.n_features_with_missing > 0)
_eda_high_pn = bool(profile and getattr(profile, 'p_n_ratio', 0) > 0.3)
_eda_collinearity = any('collinearity' in str(k).lower() or 'multicollinearity' in str(k).lower() for k in (eda_results or {}))

# ============================================================================
# 1. MODEL SELECTION FIRST
# ============================================================================
st.markdown("---")
st.header("Select models for preprocessing")
st.caption("Select models below; these choices drive pipeline options and are used on Train & Compare.")
task_type_det = st.session_state.get("task_type_detection") or TaskTypeDetection()
task_type_final = (getattr(task_type_det, "final", None) or (data_config.task_type if data_config else None) or "regression")
if data_config:
    data_config.task_type = task_type_final

registry_prep = _get_registry_cached()
available_prep = {
    k: v for k, v in registry_prep.items()
    if (task_type_final == "regression" and v.capabilities.supports_regression)
    or (task_type_final == "classification" and v.capabilities.supports_classification)
}
model_groups_prep: Dict[str, List[tuple]] = {}
for key, spec in available_prep.items():
    g = spec.group
    if g not in model_groups_prep:
        model_groups_prep[g] = []
    model_groups_prep[g].append((key, spec))

# Render model selection as styled cards in columns
_GROUP_ICONS = {
    "Linear": "üìè", "Tree-based": "üå≥", "Distance-based": "üìç",
    "Margin-based": "üî≤", "Probabilistic": "üé≤", "Neural": "üß†",
}
for group_name in sorted(model_groups_prep.keys()):
    icon = _GROUP_ICONS.get(group_name, "üì¶")
    st.markdown(f"#### {icon} {group_name}")
    models_in_group = model_groups_prep[group_name]
    cols = st.columns(min(len(models_in_group), 3))
    for idx, (model_key, spec) in enumerate(models_in_group):
        ck = f"train_model_{model_key}"
        with cols[idx % len(cols)]:
            is_selected = st.session_state.get(ck, False)
            border_color = "#667eea" if is_selected else "#e2e8f0"
            bg_color = "#f0f0ff" if is_selected else "#ffffff"
            notes_text = "; ".join(spec.capabilities.notes) if spec.capabilities.notes else ""
            check_icon = "‚úÖ" if is_selected else ""
            _desc_map = {
                "ridge": "L2-regularized linear model. Good baseline.",
                "lasso": "L1-regularized; performs feature selection.",
                "elasticnet": "Combines L1 + L2 penalties.",
                "logreg": "Standard linear classifier. Interpretable.",
                "glm": "Ordinary least squares or logistic regression.",
                "huber": "Robust to outliers in the target variable.",
                "knn_reg": "Predicts from nearby neighbors. No assumptions.",
                "knn_clf": "Classifies by majority vote of neighbors.",
                "rf": "Ensemble of decorrelated trees. Robust default.",
                "extratrees_reg": "Extremely randomized trees. Fast.",
                "extratrees_clf": "Extremely randomized trees. Fast.",
                "histgb_reg": "Fast gradient boosting with histogram binning.",
                "histgb_clf": "Fast gradient boosting with histogram binning.",
                "svr": "Finds optimal margin hyperplane for regression.",
                "svc": "Finds optimal margin hyperplane for classification.",
                "gaussian_nb": "Assumes feature independence. Very fast.",
                "lda": "Maximizes class separability. Linear boundaries.",
                "nn": "Multi-layer perceptron. Flexible, needs tuning.",
            }
            desc = _desc_map.get(model_key, notes_text)
            st.markdown(f"""
            <div style="border: 2px solid {border_color}; border-radius: 10px; padding: 0.75rem 1rem;
                        background: {bg_color}; margin-bottom: 0.5rem; transition: all 0.15s;
                        box-shadow: {'0 2px 8px rgba(102,126,234,0.15)' if is_selected else 'none'};">
                <div style="display: flex; justify-content: space-between; align-items: center;">
                    <strong style="font-size: 0.95rem;">{spec.name}</strong>
                    <span style="font-size: 0.75rem; background: {'#667eea' if is_selected else '#e2e8f0'};
                           color: {'white' if is_selected else '#64748b'}; padding: 2px 8px;
                           border-radius: 12px;">{group_name}</span>
                </div>
                <div style="font-size: 0.8rem; color: #64748b; margin-top: 4px;">{desc}</div>
                {f'<div style="margin-top: 4px; font-size: 0.8rem;">{check_icon}</div>' if is_selected else ''}
            </div>
            """, unsafe_allow_html=True)
            st.checkbox(
                "Select",
                value=is_selected,
                key=ck,
                label_visibility="collapsed",
            )

selected_models = [k.replace("train_model_", "") for k, v in st.session_state.items() if k.startswith("train_model_") and v]
if selected_models:
    st.success(f"‚úÖ **{len(selected_models)} model(s) selected:** {', '.join(m.upper() for m in selected_models)}")
else:
    st.info("Select at least one model above. Each gets its own preprocessing pipeline.")

# ============================================================================
# 2. PREPROCESSING CONFIGURATION
# ============================================================================
st.markdown("---")
st.header("‚öôÔ∏è Configure Preprocessing")

preprocessing_config = st.session_state.get("preprocessing_config", {}) or {}
st.session_state.preprocessing_config = preprocessing_config

# Simple vs Advanced mode toggle
config_mode = st.radio(
    "Configuration mode",
    ["üü¢ Smart Defaults (recommended)", "üîß Advanced (full control)"],
    index=0,
    key="preprocess_config_mode",
    horizontal=True,
    help="Smart Defaults auto-configures based on your data and EDA findings. Advanced gives full control over every option.",
)
use_smart_defaults = "Smart" in config_mode

if use_smart_defaults:
    render_guidance(
        "<strong>Smart Defaults</strong> will automatically configure preprocessing based on your data profile: "
        "missing values ‚Üí median imputation + missing indicators; "
        "outliers detected ‚Üí robust scaling; "
        "linear models ‚Üí standard scaling; "
        "tree models ‚Üí minimal preprocessing. "
        "You can switch to Advanced mode anytime to fine-tune."
    )

    # Auto-detect best settings from EDA
    _auto_scaling = "robust" if _eda_outliers else "standard"
    _auto_imputation = "median"
    _auto_missing_indicators = _eda_missing
    _auto_outlier = "none"  # Let robust scaling handle outliers rather than clipping

    st.markdown("**Auto-detected settings:**")
    auto_cols = st.columns(3)
    with auto_cols[0]:
        st.markdown(f"- Scaling: **{_auto_scaling}**" + (" *(outliers detected)*" if _eda_outliers else ""))
        st.markdown(f"- Imputation: **{_auto_imputation}**")
    with auto_cols[1]:
        st.markdown(f"- Missing indicators: **{'Yes' if _auto_missing_indicators else 'No'}**")
        st.markdown(f"- Categorical: **one-hot encoding**")
    with auto_cols[2]:
        st.markdown(f"- Outlier treatment: **{_auto_outlier}**")
        st.markdown(f"- Feature augmentation: **none**")

    st.caption("These defaults are applied to all selected models. Model-specific adjustments (e.g., enabling scaling for SVM) are handled automatically.")

# Interpretability preference (both modes)
_imode_opts = ["high", "balanced", "performance"]
_imode_stored = st.session_state.get("interpretability_mode", "balanced")
_imode_idx = _imode_opts.index(_imode_stored) if _imode_stored in _imode_opts else 1
interpretability_mode = st.selectbox(
    "Interpretability preference",
    _imode_opts,
    index=_imode_idx,
    key="interpretability_mode",
    format_func=lambda x: {"high": "üîç High (simple pipelines, no PCA/KMeans)", "balanced": "‚öñÔ∏è Balanced (recommended)", "performance": "üöÄ Performance (all transforms allowed)"}[x],
    help="Controls whether advanced transforms (PCA, KMeans, log) are allowed. High keeps pipelines simple and explainable.",
)

# When using smart defaults, set session state values automatically
if use_smart_defaults:
    # Smart defaults: auto-upgrade scaling for models that need it
    for _mk in (selected_models if selected_models else ["default"]):
        _spec = registry_prep.get(_mk)
        _needs_scale = _spec and _spec.capabilities and getattr(_spec.capabilities, "requires_scaled_numeric", False)
        st.session_state[f"preprocess_{_mk}_numeric_scaling"] = "standard" if _needs_scale else _auto_scaling
        st.session_state[f"preprocess_{_mk}_numeric_imputation"] = _auto_imputation
        st.session_state[f"preprocess_{_mk}_numeric_missing_indicators"] = _auto_missing_indicators
        st.session_state[f"preprocess_{_mk}_numeric_outlier_treatment"] = _auto_outlier
        st.session_state[f"preprocess_{_mk}_numeric_power_transform"] = "none"
        st.session_state[f"preprocess_{_mk}_categorical_imputation"] = "most_frequent"
        st.session_state[f"preprocess_{_mk}_categorical_encoding"] = "onehot"
        st.session_state[f"preprocess_{_mk}_numeric_log_transform"] = False
        st.session_state[f"preprocess_{_mk}_use_pca"] = False
        st.session_state[f"preprocess_{_mk}_use_kmeans"] = False
        st.session_state[f"preprocess_{_mk}_plausibility_gating"] = False
        st.session_state[f"preprocess_{_mk}_unit_harmonization"] = False

def _interpretability_guidance(
    profile: Optional[Any],
    insights: List[Dict],
    eda_results: Dict,
    selected: List[str],
    registry: Dict,
) -> List[str]:
    bullets = []
    pn = getattr(profile, "p_n_ratio", 0) if profile else 0
    has_collinearity = any("collinearity" in str(k).lower() or "multicollinearity" in str(k).lower() for k in (eda_results or {}))
    has_outliers = bool(profile and profile.features_with_outliers)
    linear = [m for m in selected if m in ["ridge", "lasso", "elasticnet", "glm", "logreg"]]
    trees = [m for m in selected if m in ["rf", "extratrees_reg", "extratrees_clf", "histgb_reg", "histgb_clf"]]
    nn_only = selected and all(m == "nn" for m in selected)
    if pn > 0.3 and linear:
        bullets.append(f"High feature-to-sample ratio ({pn:.2f}) and linear models ‚Üí **performance** can help accuracy; **high** keeps pipelines simple for stakeholders.")
    if has_collinearity and linear:
        bullets.append("Collinearity detected and linear models ‚Üí **balanced** or **performance**; consider PCA or regularization.")
    if has_outliers and (linear or selected and "nn" in selected):
        bullets.append("Outliers present ‚Üí **performance** (e.g. robust scaling) or **balanced**; **high** avoids extra transforms.")
    if trees and not linear and not (selected and "nn" in selected):
        bullets.append("Mostly tree models ‚Üí interpretability preference mainly affects optional preprocessing (log, PCA, KMeans); **balanced** is a reasonable default.")
    if nn_only:
        bullets.append("Neural network only ‚Üí interpretability affects only preprocessing; use **performance** if you care more about accuracy than explainability.")
    if not bullets:
        bullets.append("**Balanced** is a reasonable default. Use **high** when you need simple, explainable pipelines; **performance** when accuracy matters most.")
    return bullets[:4]

_guidance = _interpretability_guidance(profile, insights, eda_results or {}, selected_models, registry_prep)
if _guidance:
    st.caption("**Interpretability guidance:**")
    for _g in _guidance:
        st.caption(f"‚Ä¢ {_g}")

_config_keys = ["default"] if not selected_models else selected_models

def _cfg(mk: str, key: str, default: Any, from_global: bool = True) -> Any:
    k = f"preprocess_{mk}_{key}"
    v = st.session_state.get(k)
    if v is not None:
        return v
    if from_global and preprocessing_config:
        return preprocessing_config.get(key, default)
    return default

if use_smart_defaults:
    pass  # Smart defaults already set in session state above; skip manual config
else:
    st.markdown("---")
    st.subheader("Per-Model Configuration")
    st.caption("Expand each model to customize its preprocessing pipeline. Settings apply per-model so you can tailor preprocessing to each algorithm's needs.")

    # Helper: detect high-cardinality categoricals
    _high_card_feats = [f for f in categorical_features if df[f].nunique() > 10] if categorical_features else []

    for _mk in _config_keys:
        with st.expander(f"üîß Configure {_mk.upper()}", expanded=(len(_config_keys) == 1)):

            # ‚îÄ‚îÄ 1. üßπ Handle Missing Data ‚îÄ‚îÄ
            st.markdown("#### üßπ Handle Missing Data")
            st.caption("*Why it matters:* Most models cannot handle NaN values. How you fill gaps affects both accuracy and what your results mean ‚Äî reviewers will scrutinize this.")
            if _eda_missing:
                _miss_pct = getattr(profile, 'missing_pct_overall', None)
                _miss_msg = f"‚ö†Ô∏è EDA detected missing values" + (f" (~{_miss_pct:.1f}% overall)" if _miss_pct else "") + "."
                if _miss_pct and _miss_pct > 5:
                    _miss_msg += " With >5% missingness, consider **MICE** for publication-grade imputation."
                st.warning(_miss_msg)
            _c_miss1, _c_miss2 = st.columns(2)
            with _c_miss1:
                _imp_options = ["median", "mean", "iterative (MICE)", "constant"]
                _imp_help = {
                    "median": "Robust to skewed distributions. Most common default.",
                    "mean": "Assumes symmetry. Sensitive to outliers ‚Äî use only if features are roughly Gaussian.",
                    "iterative (MICE)": "Gold standard for clinical research. Models each feature conditioned on others. Recommended when >5% data is missing (Rubin, 1987).",
                    "constant": "Fills with a fixed value (e.g., 0). Use when missingness has domain meaning.",
                }
                _stored_imp = _cfg(_mk, "numeric_imputation", "median")
                if _stored_imp == "iterative":
                    _stored_imp = "iterative (MICE)"
                _nim = safe_option_index(_imp_options, _stored_imp, "median")
                _sel_imp = st.selectbox(
                    "Numeric imputation",
                    _imp_options,
                    index=_nim,
                    key=f"preprocess_{_mk}_numeric_imputation_display",
                    help="How to fill missing numeric values before modeling.",
                )
                # Map display value back to internal key
                _imp_internal = "iterative" if "MICE" in _sel_imp else _sel_imp
                st.session_state[f"preprocess_{_mk}_numeric_imputation"] = _imp_internal
                st.caption(f"‚ÑπÔ∏è {_imp_help.get(_sel_imp, '')}")
                st.checkbox(
                    "Add missing-data indicator columns",
                    value=bool(_cfg(_mk, "numeric_missing_indicators", False)),
                    key=f"preprocess_{_mk}_numeric_missing_indicators",
                    help="Adds binary columns (feature_missing = 0/1) so the model can learn whether missingness itself is informative (MNAR pattern).",
                )
            with _c_miss2:
                _cim = safe_option_index(["most_frequent", "constant"], _cfg(_mk, "categorical_imputation", "most_frequent"), "most_frequent")
                st.selectbox(
                    "Categorical imputation",
                    ["most_frequent", "constant"],
                    index=_cim,
                    key=f"preprocess_{_mk}_categorical_imputation",
                    help="'Most frequent' fills with the mode. 'Constant' fills with a placeholder category.",
                )

            # ‚îÄ‚îÄ 2. üìè Scale & Transform ‚îÄ‚îÄ
            st.markdown("#### üìè Scale & Transform")
            st.caption("*Why it matters:* Linear models, SVMs, and neural nets are sensitive to feature scale. Tree-based models (Random Forest, XGBoost) are scale-invariant ‚Äî scaling won't hurt but is unnecessary.")
            _scale_options = ["standard", "robust", "minmax", "none"]
            _scale_help = {
                "standard": "Zero-mean, unit-variance (z-score). Best when features are roughly Gaussian. Sensitive to outliers.",
                "robust": "Median/IQR-based. Resistant to outliers ‚Äî recommended when EDA found outliers.",
                "minmax": "Scales to [0, 1] range. Useful for neural nets. Sensitive to outliers.",
                "none": "No scaling. Fine for tree/ensemble models. Preserves raw coefficient interpretation.",
            }
            _scl = safe_option_index(_scale_options, _cfg(_mk, "numeric_scaling", "standard"), "standard")
            _sel_scale = st.selectbox(
                "Scaling method",
                _scale_options,
                index=_scl,
                key=f"preprocess_{_mk}_numeric_scaling",
                format_func=lambda x: {"standard": "Standard (z-score)", "robust": "Robust (median/IQR)", "minmax": "Min-Max [0,1]", "none": "None (raw values)"}[x],
            )
            st.caption(f"‚ÑπÔ∏è {_scale_help.get(_sel_scale, '')}")
            if _eda_outliers and _sel_scale == "standard":
                st.warning("‚ö†Ô∏è EDA found outliers ‚Äî consider **Robust** scaling instead. Standard scaling uses mean/std which are distorted by outliers.")

            _transform_options = ["none", "log1p", "yeo-johnson"]
            _transform_help = {
                "none": "No power transform applied.",
                "log1p": "log(1+x). Compresses right-skewed distributions. Requires non-negative values.",
                "yeo-johnson": "Automatically optimizes the transform parameter. Handles negative values. More general than log ‚Äî preferred for publication (Box & Cox, 1964; Yeo & Johnson, 2000).",
            }
            _stored_transform = _cfg(_mk, "numeric_power_transform", "none")
            # Backward compat: old log_transform boolean ‚Üí log1p
            if _stored_transform == "none" and bool(_cfg(_mk, "numeric_log_transform", False)):
                _stored_transform = "log1p"
            _tidx = safe_option_index(_transform_options, _stored_transform, "none")
            _sel_transform = st.selectbox(
                "Power transform",
                _transform_options,
                index=_tidx,
                key=f"preprocess_{_mk}_numeric_power_transform",
                format_func=lambda x: {"none": "None", "log1p": "Log (log(1+x))", "yeo-johnson": "Yeo-Johnson (auto-optimized)"}[x],
                help="Power transforms make skewed features more Gaussian, which helps linear models and neural nets.",
            )
            st.caption(f"‚ÑπÔ∏è {_transform_help.get(_sel_transform, '')}")
            # Map back to old log_transform key for pipeline compatibility
            st.session_state[f"preprocess_{_mk}_numeric_log_transform"] = (_sel_transform == "log1p")

            # ‚îÄ‚îÄ 3. üè∑Ô∏è Encode Categories ‚îÄ‚îÄ
            if categorical_features:
                st.markdown("#### üè∑Ô∏è Encode Categories")
                st.caption("*Why it matters:* Models need numeric inputs. How you encode categories affects feature count, model performance, and interpretability.")
                _enc_options = ["onehot", "target", "ordinal"]
                _enc_help = {
                    "onehot": "Creates a binary column per category. Safe and interpretable. Can cause feature explosion with high-cardinality variables (>10 levels).",
                    "target": "Encodes each category as the smoothed mean of the target variable. Prevents feature explosion. Risk: subtle data leakage if not done in-fold ‚Äî our pipeline uses cross-fitting to mitigate this.",
                    "ordinal": "Maps categories to integers (0, 1, 2, ‚Ä¶). Only appropriate when categories have a natural order (e.g., education level, severity grade). Incorrect use implies false ordering.",
                }
                _stored_enc = _cfg(_mk, "categorical_encoding", "onehot")
                _eidx = safe_option_index(_enc_options, _stored_enc, "onehot")
                _sel_enc = st.selectbox(
                    "Categorical encoding",
                    _enc_options,
                    index=_eidx,
                    key=f"preprocess_{_mk}_categorical_encoding",
                    format_func=lambda x: {"onehot": "One-Hot (binary columns)", "target": "Target Encoding (smoothed means)", "ordinal": "Ordinal (integer mapping)"}[x],
                )
                st.caption(f"‚ÑπÔ∏è {_enc_help.get(_sel_enc, '')}")
                if _high_card_feats and _sel_enc == "onehot":
                    st.warning(f"‚ö†Ô∏è High-cardinality categoricals detected: **{', '.join(_high_card_feats[:3])}** ({df[_high_card_feats[0]].nunique()} levels). One-hot will create many sparse columns. Consider **Target Encoding**.")
                if _sel_enc == "ordinal":
                    st.info("üí° Ordinal encoding assumes a meaningful order. If your categories are nominal (no order), use One-Hot or Target Encoding instead.")
            else:
                st.session_state[f"preprocess_{_mk}_categorical_encoding"] = "onehot"

            # ‚îÄ‚îÄ 4. ‚úÇÔ∏è Handle Outliers ‚îÄ‚îÄ
            st.markdown("#### ‚úÇÔ∏è Handle Outliers")
            st.caption("*Why it matters:* Outliers can dominate loss functions (especially MSE) and distort scaling. Tree models are naturally robust; linear/neural models are not.")
            if _eda_outliers:
                _out_feats = profile.features_with_outliers if profile else []
                st.warning(f"‚ö†Ô∏è EDA detected outliers in {len(_out_feats)} feature(s)" + (f": {', '.join(_out_feats[:5])}" if _out_feats else "") + ".")
            _c_out1, _c_out2 = st.columns(2)
            with _c_out1:
                if numeric_features:
                    _out_options = ["none", "percentile", "mad"]
                    _out_help = {
                        "none": "No outlier treatment. Appropriate for tree models or when outliers are real data points.",
                        "percentile": "Clips values outside specified percentiles (e.g., 1st‚Äì99th). Simple and effective.",
                        "mad": "Median Absolute Deviation. Flags values beyond k √ó MAD from the median. More robust than z-score.",
                    }
                    _v = _cfg(_mk, "numeric_outlier_treatment", "none")
                    _idx = safe_option_index(_out_options, _v, "none")
                    _ot = st.selectbox(
                        "Outlier treatment",
                        _out_options,
                        index=_idx,
                        key=f"preprocess_{_mk}_numeric_outlier_treatment",
                        format_func=lambda x: {"none": "None", "percentile": "Percentile clipping", "mad": "MAD-based removal"}[x],
                    )
                    st.caption(f"‚ÑπÔ∏è {_out_help.get(_ot, '')}")
                    if _ot == "percentile":
                        st.number_input("Lower percentile", 0.0, 0.1, 0.01, key=f"preprocess_{_mk}_outlier_lower_q")
                        st.number_input("Upper percentile", 0.9, 1.0, 0.99, key=f"preprocess_{_mk}_outlier_upper_q")
                    elif _ot == "mad":
                        st.number_input("MAD threshold (k)", 2.0, 6.0, 3.5, key=f"preprocess_{_mk}_outlier_mad_threshold", help="Values beyond k √ó MAD from the median are treated as outliers. 3.5 is a common default.")
                else:
                    _ot = "none"
            with _c_out2:
                _pg = st.checkbox(
                    "Domain-specific range filtering",
                    value=bool(_cfg(_mk, "plausibility_gating", False)),
                    key=f"preprocess_{_mk}_plausibility_gating",
                    help="Apply domain-specific plausible ranges (e.g., NHANES reference ranges for biomarkers). Values outside the range are clipped or filtered.",
                )
                if _pg:
                    _pm = safe_option_index(["clip", "filter"], _cfg(_mk, "plausibility_mode", "clip"), "clip")
                    st.radio(
                        "Range filter mode",
                        ["clip", "filter"],
                        index=_pm,
                        format_func=lambda x: "Clip to NaN (keep rows)" if x == "clip" else "Remove out-of-range rows",
                        key=f"preprocess_{_mk}_plausibility_mode",
                        horizontal=True,
                    )
                st.checkbox(
                    "Unit harmonization",
                    value=bool(_cfg(_mk, "unit_harmonization", False)),
                    key=f"preprocess_{_mk}_unit_harmonization",
                    help="Auto-detect and convert mixed units (e.g., mg/dL ‚Üî mmol/L) before modeling.",
                )

            # ‚îÄ‚îÄ 5. üî¨ Advanced: Dimensionality Reduction & Feature Engineering ‚îÄ‚îÄ
            st.markdown("#### üî¨ Advanced")
            st.caption("‚ö†Ô∏è *These options modify your feature space in ways that affect interpretability. Use only with clear justification ‚Äî reviewers will ask why.*")

            # PCA ‚Äî Dimensionality Reduction
            _up = bool(_cfg(_mk, "use_pca", False))
            _up = st.checkbox(
                "PCA ‚Äî Dimensionality Reduction",
                value=_up,
                key=f"preprocess_{_mk}_use_pca",
                help="Replaces original features with principal components (PC1, PC2, ‚Ä¶). Eliminates multicollinearity but DESTROYS feature interpretability.",
            )
            if _up:
                st.warning(
                    "‚ö†Ô∏è **Interpretability impact:** After PCA, you can no longer say 'BMI was the strongest predictor.' "
                    "SHAP values will refer to PC1, PC2, etc. Use only when: (1) severe multicollinearity, "
                    "(2) features >> samples, or (3) black-box model where only prediction accuracy matters."
                )
                if _eda_collinearity:
                    st.info("‚úÖ Collinearity was detected in EDA ‚Äî PCA may be justified here.")
                if _eda_high_pn:
                    st.info("‚úÖ High feature-to-sample ratio detected ‚Äî PCA can help reduce dimensionality.")
                _maxc = max(1, min(50, len(numeric_features) + (len(categorical_features) * 5) if categorical_features else len(numeric_features)))
                _pn = _cfg(_mk, "pca_n_components", 10)
                _fix = isinstance(_pn, (int, type(1)))
                _pmode = st.radio("PCA mode", ["Fixed Components", "Variance Threshold"], index=0 if _fix else 1, key=f"preprocess_{_mk}_pca_mode")
                if _pmode == "Fixed Components":
                    _defn = min(int(_pn), _maxc) if isinstance(_pn, (int, float)) else min(10, _maxc)
                    st.number_input("Components", 1, _maxc, _defn, key=f"preprocess_{_mk}_pca_n_components")
                else:
                    _pv = 0.95 if not isinstance(_pn, (int, float)) or _pn > 1 else float(_pn)
                    st.slider("Variance explained", 0.5, 0.99, _pv, 0.05, key=f"preprocess_{_mk}_pca_n_components", help="Retain enough components to explain this fraction of total variance.")
                st.checkbox("Whiten", value=bool(_cfg(_mk, "pca_whiten", False)), key=f"preprocess_{_mk}_pca_whiten", help="Decorrelates and normalizes components to unit variance. Useful for downstream algorithms that assume isotropic data.")

            # KMeans ‚Äî Cluster-based Feature Engineering
            _uk = bool(_cfg(_mk, "use_kmeans_features", False))
            _uk = st.checkbox(
                "üß™ Cluster-based features (experimental)",
                value=_uk,
                key=f"preprocess_{_mk}_use_kmeans",
                help="Adds distance-to-centroid columns that capture nonlinear cluster structure in your data.",
            )
            if _uk:
                st.warning(
                    "‚ö†Ô∏è **Experimental feature.** Adds derived columns (distance to each KMeans centroid). "
                    "Increases feature count. Makes SHAP/coefficient interpretation harder ‚Äî "
                    "'distance to cluster 3' is not meaningful to domain experts. "
                    "Most useful for neural nets or when you suspect latent subgroups in your data."
                )
                st.number_input("Number of clusters", 2, 20, int(_cfg(_mk, "kmeans_n_clusters", 5)), key=f"preprocess_{_mk}_kmeans_n_clusters")
                st.checkbox("Add distance features", value=bool(_cfg(_mk, "kmeans_add_distances", True)), key=f"preprocess_{_mk}_kmeans_distances")
                st.checkbox("Add one-hot cluster labels", value=bool(_cfg(_mk, "kmeans_add_onehot", False)), key=f"preprocess_{_mk}_kmeans_onehot")

# Pipeline summary before building
st.markdown("---")
if use_smart_defaults and selected_models:
    st.markdown("**üìã Pipeline Summary** ‚Äî what will be built:")
    _summary_cols = st.columns(min(len(selected_models), 4))
    for _si, _sm in enumerate(selected_models):
        with _summary_cols[_si % len(_summary_cols)]:
            _spec = registry_prep.get(_sm)
            _needs_scale = _spec and _spec.capabilities and getattr(_spec.capabilities, "requires_scaled_numeric", False)
            _effective_scaling = "standard" if _needs_scale else _auto_scaling
            st.markdown(f"""
            <div style="border: 1px solid #e2e8f0; border-radius: 8px; padding: 0.6rem; margin-bottom: 0.4rem; font-size: 0.85rem;">
                <strong>{_sm.upper()}</strong><br/>
                Scale: {_effective_scaling} ¬∑ Impute: {_auto_imputation}<br/>
                {"Missing indicators ‚úì" if _auto_missing_indicators else ""}
                {"¬∑ Scaling auto-upgraded" if _needs_scale and _auto_scaling != "standard" else ""}
            </div>
            """, unsafe_allow_html=True)

if st.button("üî® Build Pipelines", type="primary", key="preprocess_build_button"):
    try:
        t0 = time.perf_counter()
        with st.spinner("Building pipelines..."):
            _sel = [k.replace("train_model_", "") for k, v in st.session_state.items() if k.startswith("train_model_") and v]
            registry = _get_registry_cached()
            model_keys = _sel if _sel else ["default"]

            def _get(mk: str, key: str, default: Any) -> Any:
                return st.session_state.get(f"preprocess_{mk}_{key}", default)

            any_unit = any(_get(mk, "unit_harmonization", False) for mk in model_keys)
            unit_overrides = st.session_state.get("unit_overrides", {})
            unit_config = build_unit_harmonization_config(df, numeric_features, unit_overrides) if any_unit else None
            any_plaus = any_unit and any(_get(mk, "plausibility_gating", False) for mk in model_keys)
            plausibility_bounds = build_plausibility_bounds(numeric_features, unit_config["conversion_factors"]) if (unit_config and any_plaus) else None

            def apply_interpretability_overrides(c: Dict[str, Any], imode: str) -> List[str]:
                notes = []
                if imode != "high":
                    return notes
                if c.get("numeric_log_transform") or c.get("numeric_power_transform", "none") != "none":
                    c["numeric_log_transform"] = False
                    c["numeric_power_transform"] = "none"
                    notes.append("Disabled power transform to preserve interpretability.")
                if c.get("use_pca"):
                    c["use_pca"] = False
                    notes.append("Disabled PCA for interpretability.")
                if c.get("use_kmeans_features"):
                    c["use_kmeans_features"] = False
                    notes.append("Disabled KMeans features for interpretability.")
                return notes

            def apply_model_requirements(c: Dict[str, Any], caps: Any) -> List[str]:
                notes = []
                if caps and getattr(caps, "requires_scaled_numeric", False) and c.get("numeric_scaling") == "none":
                    c["numeric_scaling"] = "standard"
                    notes.append("Enabled standard scaling (model requires scaling).")
                return notes

            pipelines_by_model = {}
            configs_by_model = {}
            any_filter = any_plaus and plausibility_bounds and any(
                _get(mk, "plausibility_mode", "clip") == "filter" and _get(mk, "plausibility_gating", False)
                for mk in model_keys
            )
            if any_filter:
                uf_list = unit_config["conversion_factors"] if unit_config else None
                filtered_df = apply_plausibility_filter(
                    df, numeric_features, plausibility_bounds, uf_list
                )
                st.session_state["filtered_data"] = filtered_df
                X_sample = filtered_df[all_features]
            else:
                st.session_state.pop("filtered_data", None)
                X_sample = df[all_features]
            imode = st.session_state.get("interpretability_mode", "balanced")

            for model_key in model_keys:
                ot = _get(model_key, "numeric_outlier_treatment", "none")
                params = {}
                if ot == "percentile":
                    params = {"lower_q": float(_get(model_key, "outlier_lower_q", 0.01)), "upper_q": float(_get(model_key, "outlier_upper_q", 0.99))}
                elif ot == "mad":
                    params = {"threshold": float(_get(model_key, "outlier_mad_threshold", 3.5))}

                use_unit = _get(model_key, "unit_harmonization", False)
                use_plaus = _get(model_key, "plausibility_gating", False)
                pca_mode = _get(model_key, "pca_mode", "Fixed Components")
                pn = _get(model_key, "pca_n_components", 10)
                pca_int = pca_mode == "Fixed Components" and (isinstance(pn, (int, float)) and (pn >= 1 and pn == int(pn)))

                model_config = {
                    "numeric_features": numeric_features,
                    "categorical_features": categorical_features,
                    "numeric_imputation": _get(model_key, "numeric_imputation", "median"),
                    "numeric_scaling": _get(model_key, "numeric_scaling", "standard"),
                    "numeric_log_transform": bool(_get(model_key, "numeric_log_transform", False)),
                    "numeric_power_transform": _get(model_key, "numeric_power_transform", "none"),
                    "numeric_missing_indicators": bool(_get(model_key, "numeric_missing_indicators", False)),
                    "numeric_outlier_treatment": ot,
                    "numeric_outlier_params": params,
                    "categorical_imputation": _get(model_key, "categorical_imputation", "most_frequent"),
                    "categorical_encoding": _get(model_key, "categorical_encoding", "onehot"),
                    "use_kmeans_features": bool(_get(model_key, "use_kmeans", False)),
                    "kmeans_n_clusters": int(_get(model_key, "kmeans_n_clusters", 5)),
                    "kmeans_add_distances": bool(_get(model_key, "kmeans_distances", True)),
                    "kmeans_add_onehot": bool(_get(model_key, "kmeans_onehot", False)),
                    "use_pca": bool(_get(model_key, "use_pca", False)),
                    "pca_n_components": int(pn) if pca_int else (float(pn) if pca_mode == "Variance Threshold" and isinstance(pn, (int, float)) else (0.95 if _get(model_key, "use_pca", False) else None)),
                    "pca_whiten": bool(_get(model_key, "pca_whiten", False)),
                    "unit_harmonization": use_unit,
                    "plausibility_gating": use_plaus,
                    "plausibility_mode": _get(model_key, "plausibility_mode", "clip"),
                    "interpretability_mode": imode,
                }
                if unit_config:
                    model_config["unit_harmonization_config"] = unit_config
                if plausibility_bounds:
                    model_config["plausibility_bounds"] = plausibility_bounds

                override_notes = []
                spec = registry.get(model_key)
                caps = spec.capabilities if spec else None
                override_notes.extend(apply_interpretability_overrides(model_config, imode))
                override_notes.extend(apply_model_requirements(model_config, caps))

                uf = unit_config["conversion_factors"] if unit_config and use_unit else None
                pb = plausibility_bounds if use_plaus and plausibility_bounds else None
                pmode = model_config["plausibility_mode"]

                temp_pipeline = build_preprocessing_pipeline(
                    numeric_features=numeric_features,
                    categorical_features=categorical_features,
                    numeric_imputation=model_config["numeric_imputation"],
                    numeric_scaling=model_config["numeric_scaling"],
                    numeric_log_transform=model_config["numeric_log_transform"],
                    numeric_power_transform=model_config.get("numeric_power_transform", "none"),
                    numeric_missing_indicators=model_config["numeric_missing_indicators"],
                    numeric_outlier_treatment=model_config["numeric_outlier_treatment"],
                    numeric_outlier_params=model_config["numeric_outlier_params"],
                    unit_harmonization_factors=uf,
                    plausibility_bounds=pb,
                    plausibility_mode=pmode,
                    categorical_imputation=model_config["categorical_imputation"],
                    categorical_encoding=model_config["categorical_encoding"],
                    use_kmeans_features=model_config["use_kmeans_features"],
                    kmeans_n_clusters=model_config["kmeans_n_clusters"],
                    kmeans_add_distances=model_config["kmeans_add_distances"],
                    kmeans_add_onehot=model_config["kmeans_add_onehot"],
                    use_pca=False,
                    random_state=st.session_state.get("random_seed", 42),
                )
                temp_pipeline.fit(X_sample)
                X_temp = temp_pipeline.transform(X_sample)
                if hasattr(X_temp, "toarray"):
                    X_temp = X_temp.toarray()
                actual_n = X_temp.shape[1]
                if model_config["use_pca"] and isinstance(model_config["pca_n_components"], int) and model_config["pca_n_components"] > actual_n:
                    model_config["pca_n_components"] = actual_n
                    override_notes.append(f"Adjusted PCA components to {actual_n} (available features).")

                pipeline = build_preprocessing_pipeline(
                    numeric_features=numeric_features,
                    categorical_features=categorical_features,
                    numeric_imputation=model_config["numeric_imputation"],
                    numeric_scaling=model_config["numeric_scaling"],
                    numeric_log_transform=model_config["numeric_log_transform"],
                    numeric_power_transform=model_config.get("numeric_power_transform", "none"),
                    numeric_missing_indicators=model_config["numeric_missing_indicators"],
                    numeric_outlier_treatment=model_config["numeric_outlier_treatment"],
                    numeric_outlier_params=model_config["numeric_outlier_params"],
                    unit_harmonization_factors=uf,
                    plausibility_bounds=pb,
                    plausibility_mode=pmode,
                    categorical_imputation=model_config["categorical_imputation"],
                    categorical_encoding=model_config["categorical_encoding"],
                    use_kmeans_features=model_config["use_kmeans_features"],
                    kmeans_n_clusters=model_config["kmeans_n_clusters"],
                    kmeans_add_distances=model_config["kmeans_add_distances"],
                    kmeans_add_onehot=model_config["kmeans_add_onehot"],
                    use_pca=model_config["use_pca"],
                    pca_n_components=model_config["pca_n_components"],
                    pca_whiten=model_config["pca_whiten"],
                    random_state=st.session_state.get("random_seed", 42),
                )
                pipeline.fit(X_sample)
                X_transformed = pipeline.transform(X_sample)
                if hasattr(X_transformed, "toarray"):
                    X_transformed = X_transformed.toarray()
                model_config["n_output_features"] = X_transformed.shape[1]
                model_config["overrides"] = override_notes
                pipelines_by_model[model_key] = pipeline
                configs_by_model[model_key] = model_config

            base_config = {"numeric_features": numeric_features, "categorical_features": categorical_features}
            set_preprocessing_pipelines(pipelines_by_model, configs_by_model, base_config)
            _built = [k for k in pipelines_by_model.keys() if k != "default"]
            st.session_state["preprocess_built_model_keys"] = _built

            # Save preprocessing summary for methods section generation
            _first_cfg = next(iter(configs_by_model.values()), {})
            _imp_method = _first_cfg.get("numeric_imputation", "median")
            _imp_label = {"median": "median imputation", "mean": "mean imputation",
                          "iterative": "multiple imputation by chained equations (MICE)",
                          "constant": "constant value imputation"}.get(_imp_method, _imp_method)
            _scale_method = _first_cfg.get("numeric_scaling", "standard")
            _scale_label = {"standard": "z-score standardization (zero mean, unit variance)",
                            "robust": "robust scaling (median and IQR)",
                            "minmax": "min-max normalization to [0, 1]",
                            "none": "no scaling applied"}.get(_scale_method, _scale_method)
            _enc_method = _first_cfg.get("categorical_encoding", "onehot")
            _enc_label = {"onehot": "one-hot encoding", "target": "target encoding",
                          "ordinal": "ordinal encoding"}.get(_enc_method, _enc_method)
            _outlier = _first_cfg.get("numeric_outlier_treatment", "none")
            _outlier_label = {"none": "no explicit outlier treatment",
                              "percentile": "percentile-based winsorization",
                              "mad": "MAD-based outlier clipping"}.get(_outlier, _outlier)
            _transform = _first_cfg.get("numeric_power_transform", "none")
            if _first_cfg.get("numeric_log_transform"):
                _transform = "log1p"
            _transform_label = {"none": "no additional transformation",
                                "yeo-johnson": "Yeo-Johnson power transformation",
                                "log1p": "log(1+x) transformation"}.get(_transform, _transform)
            st.session_state["preprocessing_summary"] = {
                "missing_data": {"method": _imp_method, "label": _imp_label,
                                 "indicators": _first_cfg.get("numeric_missing_indicators", False)},
                "scaling": {"method": _scale_method, "label": _scale_label},
                "encoding": {"method": _enc_method, "label": _enc_label},
                "outliers": {"method": _outlier, "label": _outlier_label,
                             "params": _first_cfg.get("numeric_outlier_params", {})},
                "transforms": {"method": _transform, "label": _transform_label},
                "n_numeric": len(numeric_features),
                "n_categorical": len(categorical_features),
                "models_configured": list(configs_by_model.keys()),
            }

            # Model-aware preprocessing insights for Train & Compare and Report
            high_card = bool(profile and getattr(profile, "high_cardinality_features", None))
            model_check_bullets = []
            for mk, cfg in configs_by_model.items():
                spec = registry.get(mk)
                caps = spec.capabilities if spec else None
                scaling = cfg.get("numeric_scaling", "standard")
                ov = cfg.get("overrides", [])
                parts = [f"{mk.upper()}:"]
                if caps and getattr(caps, "requires_scaled_numeric", False):
                    if scaling == "none":
                        parts.append("model requires scaling but you used none ‚Äî consider enabling scaling.")
                    else:
                        parts.append(f"scaling enabled ({scaling}); appropriate for this model.")
                else:
                    if scaling != "none":
                        parts.append(f"scaling {scaling} (optional for tree models).")
                    else:
                        parts.append("no scaling; fine for tree models.")
                if any("interpretability" in str(o).lower() for o in ov):
                    parts.append("Interpretability overrides applied (e.g. PCA/KMeans disabled).")
                if high_card and cfg.get("categorical_encoding") == "onehot":
                    parts.append("High cardinality in EDA; one-hot may inflate feature count ‚Äî consider alternatives.")
                model_check_bullets.append(" ".join(parts))
            finding = " ".join(model_check_bullets[:5])
            if len(model_check_bullets) > 5:
                finding += " ‚Ä¶"
            add_insight(
                "preprocessing_model_checks",
                finding,
                "Review that preprocessing matches each model; adjust and rebuild if needed.",
                category="preprocessing",
            )
            add_insight(
                "preprocessing_summary",
                f"Pipelines built for {len(pipelines_by_model)} model(s): {', '.join(m.upper() for m in pipelines_by_model.keys())}.",
                "Use Train & Compare to train models; preprocessing is applied per model.",
                category="preprocessing",
            )
        elapsed = time.perf_counter() - t0
        st.session_state.setdefault("last_timings", {})["Build Pipelines"] = round(elapsed, 2)

        st.success("Preprocessing pipelines built successfully. Expand each model below to view recipe and transformed data.")
        
    except Exception as e:
        st.error(f"Error building pipeline: {e}")
        st.exception(e)

# Per-model expanders: recipe, overrides, show table, CSV export
pipelines_by_model = st.session_state.get("preprocessing_pipelines_by_model") or {}
configs_by_model = st.session_state.get("preprocessing_config_by_model") or {}
if pipelines_by_model:
    st.markdown("---")
    st.header("Pipelines by model")
    st.caption("Expand each model to view recipe and overrides. Use ¬´Show transformed table¬ª to preview values, then ¬´Download as CSV¬ª to export.")
    X_sample_preview = df[all_features]
    for model_key, pipeline in pipelines_by_model.items():
        _show = st.session_state.get(f"show_preview_{model_key}", False)
        with st.expander(f"Pipeline for {model_key.upper()}", expanded=(model_key == "default" or _show)):
            cfg = configs_by_model.get(model_key, {})
            recipe = get_pipeline_recipe(pipeline, plausibility_mode=cfg.get("plausibility_mode"))
            st.code(recipe, language=None)
            overrides = cfg.get("overrides", [])
            if overrides:
                st.caption("Overrides applied:")
                for note in overrides:
                    st.write(f"‚Ä¢ {note}")
            show_table = st.checkbox("Show transformed table", value=_show, key=f"show_preview_{model_key}")
            if show_table:
                _before = X_sample_preview.head(100)
                X_t = pipeline.transform(X_sample_preview)
                if hasattr(X_t, "toarray"):
                    X_t = X_t.toarray()
                col_names = get_feature_names_after_transform(pipeline, all_features)
                if len(col_names) != X_t.shape[1]:
                    col_names = [f"feature_{i}" for i in range(X_t.shape[1])]
                preview_df = pd.DataFrame(X_t, columns=col_names)
                _ba, _aa = st.columns(2)
                with _ba:
                    st.subheader("Before")
                    st.dataframe(_before, width="stretch")
                with _aa:
                    st.subheader("After")
                    st.dataframe(preview_df.head(100), width="stretch")
                csv_bytes = preview_df.to_csv(index=False).encode()
                st.download_button(
                    "Download as CSV",
                    data=csv_bytes,
                    file_name=f"transformed_{model_key}.csv",
                    mime="text/csv",
                    key=f"download_preview_{model_key}",
                )
    _built_names = ", ".join(k.upper() for k in pipelines_by_model.keys())
    st.success(f"‚úÖ **Pipelines ready for: {_built_names}**. Head to **Train & Compare** ‚Üí your models and preprocessing are already synced.")
    st.page_link("pages/04_Train_and_Compare.py", label="‚û°Ô∏è Go to Train & Compare", icon="üèãÔ∏è")

    if st.button("Rebuild Pipeline", key="preprocess_rebuild_button"):
        st.session_state.preprocessing_pipeline = None
        st.session_state.preprocessing_config = None
        st.session_state.preprocessing_pipelines_by_model = {}
        st.session_state.preprocessing_config_by_model = {}
        st.rerun()

# State Debug (Advanced)
with st.expander("Advanced / State Debug", expanded=False):
    st.markdown("**Current State:**")
    st.write(f"‚Ä¢ Data shape: {df.shape if df is not None else 'None'}")
    st.write(f"‚Ä¢ Target: {data_config.target_col if data_config else 'None'}")
    st.write(f"‚Ä¢ Features: {len(data_config.feature_cols) if data_config else 0}")
    st.write(f"‚Ä¢ Preprocessing pipeline: {'Built' if st.session_state.get('preprocessing_pipeline') else 'Not built'}")
    _lt = st.session_state.get("last_timings", {})
    if _lt:
        st.write("‚Ä¢ Last timings (s):", ", ".join(f"{k}={v}s" for k, v in _lt.items()))
    preprocessing_config = st.session_state.get('preprocessing_config')
    if preprocessing_config:
        st.write(f"‚Ä¢ Numeric imputation: {preprocessing_config.get('numeric_imputation', 'N/A')}")
        st.write(f"‚Ä¢ Numeric scaling: {preprocessing_config.get('numeric_scaling', 'N/A')}")
    if profile:
        st.write(f"‚Ä¢ Dataset profile available: Yes")
        st.write(f"‚Ä¢ Data sufficiency: {profile.data_sufficiency.value}")